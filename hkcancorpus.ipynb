{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PYCANTONESE_PATH = r'/home/lun/csrp/corpuses/pycantonese/'\n",
    "CORPUS_PATH = r'/home/lun/csrp/code/corpus/hkcancor/'\n",
    "OUTPUT_PATH = r'/home/lun/csrp/code/jieba-cantonese/'\n",
    "DICT_PATH = r'/home/lun/csrp/code/dictionaries/'\n",
    "\n",
    "import sys, re, glob, math, collections\n",
    "sys.path.insert(0, PYCANTONESE_PATH) # PyCantonese v0.21, modified\n",
    "import pycantonese as pc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from contextlib import redirect_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract text and pos tags from HKCanCor CHAT files\n",
    "### and save them in separate files\n",
    "#### Enable Code if this has not done prior"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def replaceCharacters(text):\n",
    "    reg_exp_dict = {\n",
    "        '':'㗎', \n",
    "#         '':'𠺢',\n",
    "        '':'噃', '':'𠺝', '':'喎',\n",
    "#         '':'尛'\n",
    "        '':'liu', '':'lung', '':'𧕴',\n",
    "        '':'喵', '\\?幾':'幾', '':'𥅾',\n",
    "#         '':'zong',\n",
    "        '':'嚕',\n",
    "#         '':'lu',\n",
    "        '':'呢', \n",
    "#         '':'le', \n",
    "        '':'𥄫',\n",
    "    }\n",
    "        \n",
    "    for replace_char, sub_char in reg_exp_dict.items():\n",
    "        text = re.sub(replace_char, sub_char, text, count=0, flags=re.DOTALL)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Function to do batch extracting text from HK Cantonese corpus data \n",
    "# i.e. the 58 annotated transcripts in http://compling.hss.ntu.edu.sg/hkcancor/\n",
    "# that are reproduced in CHAT format in PyCantonese data folder\n",
    "# Idea is to keep extracted data in separate files for sake of flexibility\n",
    "# This means something like corpus = pc.hkcancor() cannot be called\n",
    "def save_transcriptAndPOSTags():\n",
    "    chat_files = glob.glob(PYCANTONESE_PATH + 'pycantonese/data/hkcancor/*.cha')\n",
    "    \n",
    "    # a helper to save each item in hkcorpus_postag and \n",
    "    # hkcorpus_text in its own line\n",
    "    def saveFile(str_list, filename):\n",
    "        with open(CORPUS_PATH + filename % i, 'w', encoding='utf-8') as f:\n",
    "            str_list = map(lambda x: x+\"\\n\", str_list)\n",
    "            f.writelines(str_list)\n",
    "        assert(f.closed)\n",
    "    \n",
    "    def pickleDictionary(filename, prob_dict):\n",
    "        with open(OUTPUT_PATH + filename, 'wb') as f:\n",
    "            # jieba uses protocol 0 encoding for its pickle files\n",
    "            pickle.dump(prob_dict, f)\n",
    "        assert(f.closed)\n",
    "    \n",
    "    \n",
    "    for i, chat_file in enumerate(chat_files):\n",
    "        corpus = pc.read_chat(chat_file, encoding='utf-8')\n",
    "\n",
    "        # word_sents() and pos_sents() called in the following\n",
    "        # lines are customized methods in the CantoneseCHATReader \n",
    "        # class.  They are not in the official pyCantonese library\n",
    "\n",
    "        \n",
    "        # join strings in each list,\n",
    "        # replace Cantonese characters and remove leading whitespaces \n",
    "        hkcorpus_text = [replaceCharacters(\n",
    "            \" \".join(x)).strip(' ') for x in corpus.word_sents()]\n",
    "\n",
    "    #    # find files with wrongly decoded Cantonese characters\n",
    "    #     findword = re.search('|', hkcorpus_text, flags=0)\n",
    "    #     if findword:\n",
    "    #         print(chat_file)\n",
    "\n",
    "        # join strings in each list, replace symbols, \n",
    "        # remove leading whitespaces, and change pos to lower case\n",
    "        hkcorpus_postag = [\n",
    "            \" \".join(x).strip(' ').lower() for x in corpus.pos_sents()]\n",
    "        \n",
    "    \n",
    "        saveFile(hkcorpus_text, r'text/hk_cantonese_corpus_%d.txt')\n",
    "        saveFile(hkcorpus_postag, r'pos/hk_cantonese_corpus_pos_%d.txt')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "save_transcriptAndPOSTags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_size = 58\n",
    "dataframes = []\n",
    "for i in range(corpus_size):\n",
    "    with open(CORPUS_PATH + r'text/hk_cantonese_corpus_%d.txt' % i, \n",
    "        'r', encoding='utf-8') as ftext:\n",
    "        \n",
    "        # put each string in list into a list of words,\n",
    "        # removing all empty entries in latter\n",
    "        text_list = [x.split(\" \") for x in ftext.read().splitlines()]\n",
    "        text_list = [list(filter(str.strip, x )) for x in text_list]\n",
    "    assert(ftext.closed)\n",
    "    \n",
    "    \n",
    "    with open(CORPUS_PATH + r'pos/hk_cantonese_corpus_pos_%d.txt' % i,\n",
    "        'r', encoding='utf-8') as fpos:\n",
    "        \n",
    "        # put each string in list into a list of pos tags\n",
    "        # removing all empty entries in latter\n",
    "        pos_list = [x.split(\" \") for x in fpos.read().splitlines()]\n",
    "        pos_list = [list(filter(str.strip, x)) for x in pos_list]\n",
    "    assert(fpos.closed)\n",
    "    \n",
    "    \n",
    "    table = pd.DataFrame({ 'file_num': i, 'text' : text_list, 'pos' : pos_list })\n",
    "    dataframes.append(table)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePunctuations(entry):\n",
    "    removed = [re.sub(r'[\\,\"\\-\\.\\!…\\?？○#]', \"\", x, count=0) for x in entry]\n",
    "    return list(filter(None, removed)) # remove all empty strings in list\n",
    "\n",
    "def removeTrailingNumbersFromPOS(entry):\n",
    "    return [x.strip('0123456789') for x in entry]\n",
    "\n",
    "# removePunctuations(['v1', 'v', 'n', 'y', 'nr', 'nr', '?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this for all dataframes\n",
    "for index, d in enumerate(dataframes):\n",
    "    d['pos'] = d['pos'].apply(removePunctuations).apply(removeTrailingNumbersFromPOS)\n",
    "    d['text'] = d['text'].apply(removePunctuations)\n",
    "    \n",
    "    # a check to see if the pos lengths are the same as the text lengths\n",
    "    if d.pos.str.len().all() != d.text.str.len().all():\n",
    "        print (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_num</th>\n",
       "      <th>pos</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[v, v, n, y, nr, nr]</td>\n",
       "      <td>[有冇, 養, 寵物, 𡃉, 王, 美美]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[v]</td>\n",
       "      <td>[有]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[v, u, m, q, n]</td>\n",
       "      <td>[養, 咗, 兩, 隻, 狗]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[a, y]</td>\n",
       "      <td>[真, 㗎]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[r, n, y]</td>\n",
       "      <td>[乜嘢, 樣, 𡃉]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_num                   pos                   text\n",
       "0         0  [v, v, n, y, nr, nr]  [有冇, 養, 寵物, 𡃉, 王, 美美]\n",
       "1         0                   [v]                    [有]\n",
       "2         0       [v, u, m, q, n]        [養, 咗, 兩, 隻, 狗]\n",
       "3         0                [a, y]                 [真, 㗎]\n",
       "4         0             [r, n, y]             [乜嘢, 樣, 𡃉]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinASCIIWords(rowtext, rowpos):\n",
    "    def string_is_ascii(string):\n",
    "        try:\n",
    "            string.encode(encoding='ascii')\n",
    "        except UnicodeEncodeError:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    for index, (word, pos) in enumerate(zip(rowtext, rowpos)):\n",
    "        next_index = index + 1       \n",
    "        \n",
    "        while next_index < len(rowtext) and \\\n",
    "            string_is_ascii(word) and \\\n",
    "            string_is_ascii(rowtext[next_index]):\n",
    "            \n",
    "            rowtext[index] += \"_\" + rowtext[next_index]\n",
    "            rowtext.pop(next_index)\n",
    "            rowpos.pop(next_index)\n",
    "            word = rowtext[index] # reset the word\n",
    "\n",
    "    return rowtext, rowpos\n",
    "\n",
    "\n",
    "# do this for all dataframes\n",
    "for d in dataframes:\n",
    "    result =  d.apply(lambda row: joinASCIIWords(\n",
    "        row['text'], row['pos']), axis=1).apply(pd.Series)\n",
    "    d['text'] = result[0]\n",
    "    d['pos'] = result[1]\n",
    "    \n",
    "del result\n",
    "\n",
    "# x = ['c', 'v', 'xn', 'xn', 'xn', 'q']\n",
    "# y = ['跟住', '買', 'fax', 'modem', 'modem', '個']\n",
    "# joinASCIIWords(y, x)\n",
    "\n",
    "# joinASCIIWords(['跟住', '買', '個', 'fax', 'modem', '而家', '幾百', '蚊', '啫', '嗎'])\n",
    "# joinASCIIWords(['跟住', '買', '個', 'fax', 'modem', 'hello'])\n",
    "# joinASCIIWords(['fax', 'modem', 'hello','跟住', 'hello','買', '個'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_num</th>\n",
       "      <th>pos</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[v, v, n, y, nr, nr]</td>\n",
       "      <td>[有冇, 養, 寵物, 𡃉, 王, 美美]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[v]</td>\n",
       "      <td>[有]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[v, u, m, q, n]</td>\n",
       "      <td>[養, 咗, 兩, 隻, 狗]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[a, y]</td>\n",
       "      <td>[真, 㗎]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[r, n, y]</td>\n",
       "      <td>[乜嘢, 樣, 𡃉]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_num                   pos                   text\n",
       "0         0  [v, v, n, y, nr, nr]  [有冇, 養, 寵物, 𡃉, 王, 美美]\n",
       "1         0                   [v]                    [有]\n",
       "2         0       [v, u, m, q, n]        [養, 咗, 兩, 隻, 狗]\n",
       "3         0                [a, y]                 [真, 㗎]\n",
       "4         0             [r, n, y]             [乜嘢, 樣, 𡃉]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exempt = ['One2Free', 'A1', '323', '121', 'N64', '東方188' ]\n",
    "def fixCantoneseJupingsInWordColumn(word_list, exempt_list):\n",
    "    for index, word in enumerate(word_list):\n",
    "        if word not in exempt_list and re.search(r'[0-9]', word, re.DOTALL):\n",
    "            word = re.sub(r\"[0-9]\", \"_\", word, re.DOTALL)\n",
    "            if word[-1] == \"_\":\n",
    "                word = word[:-1]\n",
    "        word_list[index] = word\n",
    "    return word_list\n",
    "\n",
    "# test\n",
    "#fixCantoneseJupings('Zip1', words_with_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataframes:\n",
    "    d['text'] = d['text'].apply(fixCantoneseJupingsInWordColumn, exempt_list=exempt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Create a stopword list using a statistical model\n",
    "### For details in the methodology behind, see \n",
    "#### `Zou et. al 2006, \"Automatic Construction of Chinese Stop Word Lists\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a stopword list\n",
    "df_text = []\n",
    "\n",
    "for d in dataframes:\n",
    "    df_text.append(np.sum(d['text'].values) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.DataFrame({'transcript': df_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_text.head()\n",
    "total_num_text = df_text.count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = []\n",
    "for index, dt in enumerate(df_text['transcript'].values ):\n",
    "    df_words.append(pd.DataFrame(dt) )\n",
    "    numwords = df_words[index].count()[0]\n",
    "    \n",
    "    df_words[index].columns = ['word']\n",
    "    df_words[index] = df_words[index].groupby('word')['word'].count()\n",
    "    df_words[index] = pd.DataFrame(df_words[index])\n",
    "    df_words[index].columns = ['num_instances']\n",
    "    df_words[index]['word_prob'] = df_words[index]['num_instances'] / numwords\n",
    "    df_words[index]['text_num'] = index\n",
    "    df_words[index].reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = pd.concat(df_words, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>num_instances</th>\n",
       "      <th>word_prob</th>\n",
       "      <th>text_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bandai</td>\n",
       "      <td>6</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CSL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMS</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Internet</td>\n",
       "      <td>7</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kelly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  num_instances  word_prob  text_num\n",
       "0    Bandai              6   0.001929         0\n",
       "1       CSL              1   0.000321         0\n",
       "2       IMS              1   0.000321         0\n",
       "3  Internet              7   0.002250         0\n",
       "4     Kelly              1   0.000321         0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words.set_index('word', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sumN_prob = df_words.groupby('word')['word_prob'].sum()\n",
    "df_sumN_prob.rename('sum_n_prob', inplace=True)\n",
    "\n",
    "df_mean_prob = df_sumN_prob / total_num_text \n",
    "df_mean_prob.rename('mean_prob', inplace=True)\n",
    "\n",
    "# join dataframes\n",
    "df_sum_N_var_prob = df_words.join(pd.DataFrame(df_mean_prob) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum_N_var_prob.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>num_instances</th>\n",
       "      <th>word_prob</th>\n",
       "      <th>text_num</th>\n",
       "      <th>mean_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>323</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>34</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AGM</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AGM_Engineering</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AGM_Operation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AIO</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ALO</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ALevel</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AM</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AM</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>54</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AV</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>34</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A_B_C</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A_paper_two_paper_three</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Accident_investigation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Account</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Account</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Acting</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ada</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ada</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ada</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>51</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Admin</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Admin</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>57</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Alevel</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Alevel</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Alevel</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25212</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>22</td>\n",
       "      <td>0.014845</td>\n",
       "      <td>37</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25213</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>18</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>38</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25214</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>21</td>\n",
       "      <td>0.017872</td>\n",
       "      <td>39</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25215</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>50</td>\n",
       "      <td>0.022381</td>\n",
       "      <td>40</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25216</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>40</td>\n",
       "      <td>0.017072</td>\n",
       "      <td>41</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25217</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>37</td>\n",
       "      <td>0.018155</td>\n",
       "      <td>42</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25218</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>16</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>43</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25219</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>32</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>44</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25220</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>37</td>\n",
       "      <td>0.021437</td>\n",
       "      <td>45</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25221</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>4</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>46</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25222</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>14</td>\n",
       "      <td>0.012467</td>\n",
       "      <td>47</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25223</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>15</td>\n",
       "      <td>0.021962</td>\n",
       "      <td>48</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25224</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>30</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>49</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25225</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>19</td>\n",
       "      <td>0.011157</td>\n",
       "      <td>50</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25226</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>30</td>\n",
       "      <td>0.023753</td>\n",
       "      <td>51</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25227</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>37</td>\n",
       "      <td>0.019072</td>\n",
       "      <td>52</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25228</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>44</td>\n",
       "      <td>0.010787</td>\n",
       "      <td>53</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25229</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>13</td>\n",
       "      <td>0.012393</td>\n",
       "      <td>54</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25230</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>43</td>\n",
       "      <td>0.016003</td>\n",
       "      <td>55</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25231</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>56</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25232</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>50</td>\n",
       "      <td>0.009203</td>\n",
       "      <td>57</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25233</th>\n",
       "      <td>𢱕</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25234</th>\n",
       "      <td>𤓓味</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25235</th>\n",
       "      <td>𥄫</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25236</th>\n",
       "      <td>𥅾</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25237</th>\n",
       "      <td>𥇣</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25238</th>\n",
       "      <td>𦧲</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25239</th>\n",
       "      <td>𦧲</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25240</th>\n",
       "      <td>𨃩低</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25241</th>\n",
       "      <td>𨋢</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25242 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          word  num_instances  word_prob  text_num  mean_prob\n",
       "0                          121              2   0.000573        31   0.000010\n",
       "1                          323              4   0.001147        31   0.000020\n",
       "2                            A             34   0.009135        14   0.000222\n",
       "3                            A              1   0.000443        16   0.000222\n",
       "4                            A              5   0.002572        19   0.000222\n",
       "5                            A              3   0.000752        28   0.000222\n",
       "6                           A1              4   0.001075        14   0.000019\n",
       "7                          AGM              1   0.000204        23   0.000004\n",
       "8              AGM_Engineering              1   0.000204        23   0.000004\n",
       "9                AGM_Operation              1   0.000204        23   0.000004\n",
       "10                         AIO              2   0.001369        26   0.000024\n",
       "11                         ALO              2   0.000623        17   0.000011\n",
       "12                      ALevel              2   0.000537        14   0.000009\n",
       "13                          AM              2   0.000550        12   0.000092\n",
       "14                          AM              5   0.004766        54   0.000092\n",
       "15                          AV              1   0.000759        34   0.000013\n",
       "16                       A_B_C              1   0.000443        16   0.000008\n",
       "17     A_paper_two_paper_three              1   0.000269        14   0.000005\n",
       "18      Accident_investigation              1   0.000204        23   0.000004\n",
       "19                     Account              8   0.002149        14   0.000046\n",
       "20                     Account              1   0.000519        35   0.000046\n",
       "21                      Acting              1   0.000684        26   0.000012\n",
       "22                         Ada              2   0.001889         5   0.000087\n",
       "23                         Ada              3   0.001567        10   0.000087\n",
       "24                         Ada              2   0.001584        51   0.000087\n",
       "25                       Admin              2   0.000409        23   0.000013\n",
       "26                       Admin              2   0.000368        57   0.000013\n",
       "27                      Alevel              2   0.000550        12   0.000022\n",
       "28                      Alevel              1   0.000251        28   0.000022\n",
       "29                      Alevel              2   0.000490        53   0.000022\n",
       "...                        ...            ...        ...       ...        ...\n",
       "25212                        𡃉             22   0.014845        37   0.014593\n",
       "25213                        𡃉             18   0.006309        38   0.014593\n",
       "25214                        𡃉             21   0.017872        39   0.014593\n",
       "25215                        𡃉             50   0.022381        40   0.014593\n",
       "25216                        𡃉             40   0.017072        41   0.014593\n",
       "25217                        𡃉             37   0.018155        42   0.014593\n",
       "25218                        𡃉             16   0.007452        43   0.014593\n",
       "25219                        𡃉             32   0.008340        44   0.014593\n",
       "25220                        𡃉             37   0.021437        45   0.014593\n",
       "25221                        𡃉              4   0.005168        46   0.014593\n",
       "25222                        𡃉             14   0.012467        47   0.014593\n",
       "25223                        𡃉             15   0.021962        48   0.014593\n",
       "25224                        𡃉             30   0.014225        49   0.014593\n",
       "25225                        𡃉             19   0.011157        50   0.014593\n",
       "25226                        𡃉             30   0.023753        51   0.014593\n",
       "25227                        𡃉             37   0.019072        52   0.014593\n",
       "25228                        𡃉             44   0.010787        53   0.014593\n",
       "25229                        𡃉             13   0.012393        54   0.014593\n",
       "25230                        𡃉             43   0.016003        55   0.014593\n",
       "25231                        𡃉              8   0.003990        56   0.014593\n",
       "25232                        𡃉             50   0.009203        57   0.014593\n",
       "25233                        𢱕              1   0.000372        29   0.000006\n",
       "25234                       𤓓味              1   0.000287        31   0.000005\n",
       "25235                        𥄫              1   0.000443        16   0.000008\n",
       "25236                        𥅾              2   0.000573        31   0.000010\n",
       "25237                        𥇣              1   0.000245        53   0.000004\n",
       "25238                        𦧲              2   0.000501        28   0.000015\n",
       "25239                        𦧲              1   0.000372        55   0.000015\n",
       "25240                       𨃩低              1   0.000491        42   0.000008\n",
       "25241                        𨋢              1   0.000475         7   0.000008\n",
       "\n",
       "[25242 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum_N_var_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum_N_var_prob['sum_N_var_prob'] = np.power(\n",
    "    df_sum_N_var_prob['word_prob'].values - df_sum_N_var_prob['mean_prob'].values, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>num_instances</th>\n",
       "      <th>word_prob</th>\n",
       "      <th>text_num</th>\n",
       "      <th>mean_prob</th>\n",
       "      <th>sum_N_var_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3550</th>\n",
       "      <td>係</td>\n",
       "      <td>334</td>\n",
       "      <td>0.061476</td>\n",
       "      <td>57</td>\n",
       "      <td>0.040375</td>\n",
       "      <td>0.000445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9304</th>\n",
       "      <td>噉</td>\n",
       "      <td>231</td>\n",
       "      <td>0.042518</td>\n",
       "      <td>57</td>\n",
       "      <td>0.020966</td>\n",
       "      <td>0.000464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>佢</td>\n",
       "      <td>202</td>\n",
       "      <td>0.037180</td>\n",
       "      <td>57</td>\n",
       "      <td>0.016647</td>\n",
       "      <td>0.000422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>係</td>\n",
       "      <td>190</td>\n",
       "      <td>0.050653</td>\n",
       "      <td>30</td>\n",
       "      <td>0.040375</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>啊</td>\n",
       "      <td>180</td>\n",
       "      <td>0.044128</td>\n",
       "      <td>53</td>\n",
       "      <td>0.031788</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  num_instances  word_prob  text_num  mean_prob  sum_N_var_prob\n",
       "3550    係            334   0.061476        57   0.040375        0.000445\n",
       "9304    噉            231   0.042518        57   0.020966        0.000464\n",
       "3329    佢            202   0.037180        57   0.016647        0.000422\n",
       "3524    係            190   0.050653        30   0.040375        0.000106\n",
       "7870    啊            180   0.044128        53   0.031788        0.000152"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum_N_var_prob.sort_values('num_instances', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum_N_var_prob = df_sum_N_var_prob.groupby('word')['sum_N_var_prob'].sum()\n",
    "df_var_prob = df_sum_N_var_prob / numwords\n",
    "df_var_prob.rename('var_prob', inplace=True)\n",
    "\n",
    "df_stopwords = pd.DataFrame({\n",
    "    'mean_prob' : df_mean_prob,\n",
    "    'var_prob' : df_var_prob,  \n",
    "    'sat_val' : df_sumN_prob / df_sum_N_var_prob\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stopwords = df_stopwords[['mean_prob', 'var_prob', 'sat_val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_prob</th>\n",
       "      <th>var_prob</th>\n",
       "      <th>sat_val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>係</th>\n",
       "      <td>0.040375</td>\n",
       "      <td>2.509103e-06</td>\n",
       "      <td>171.783880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>啊</th>\n",
       "      <td>0.031788</td>\n",
       "      <td>1.480112e-06</td>\n",
       "      <td>229.278062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>呢</th>\n",
       "      <td>0.023315</td>\n",
       "      <td>1.641020e-06</td>\n",
       "      <td>151.674803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>我</th>\n",
       "      <td>0.022638</td>\n",
       "      <td>2.498071e-06</td>\n",
       "      <td>96.744623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>噉</th>\n",
       "      <td>0.020966</td>\n",
       "      <td>5.484555e-07</td>\n",
       "      <td>408.090326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>你</th>\n",
       "      <td>0.019475</td>\n",
       "      <td>6.682196e-07</td>\n",
       "      <td>311.129658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>唔</th>\n",
       "      <td>0.017604</td>\n",
       "      <td>2.046593e-06</td>\n",
       "      <td>91.825559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>都</th>\n",
       "      <td>0.016951</td>\n",
       "      <td>2.823170e-07</td>\n",
       "      <td>640.964689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>佢</th>\n",
       "      <td>0.016647</td>\n",
       "      <td>9.024077e-07</td>\n",
       "      <td>196.939591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>好</th>\n",
       "      <td>0.016248</td>\n",
       "      <td>1.987688e-06</td>\n",
       "      <td>87.263850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>嘅</th>\n",
       "      <td>0.015212</td>\n",
       "      <td>1.073943e-06</td>\n",
       "      <td>151.218510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>就</th>\n",
       "      <td>0.015067</td>\n",
       "      <td>7.778589e-07</td>\n",
       "      <td>206.778066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>即係</th>\n",
       "      <td>0.014606</td>\n",
       "      <td>1.427891e-06</td>\n",
       "      <td>109.199204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>𡃉</th>\n",
       "      <td>0.014593</td>\n",
       "      <td>3.336680e-07</td>\n",
       "      <td>466.883536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>喇</th>\n",
       "      <td>0.012000</td>\n",
       "      <td>4.938074e-07</td>\n",
       "      <td>259.427149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>個</th>\n",
       "      <td>0.011656</td>\n",
       "      <td>1.697865e-07</td>\n",
       "      <td>732.866163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>囖</th>\n",
       "      <td>0.010902</td>\n",
       "      <td>4.264800e-07</td>\n",
       "      <td>272.897773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>有</th>\n",
       "      <td>0.010772</td>\n",
       "      <td>1.805896e-07</td>\n",
       "      <td>636.804754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>啲</th>\n",
       "      <td>0.010661</td>\n",
       "      <td>2.918955e-07</td>\n",
       "      <td>389.911264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>一</th>\n",
       "      <td>0.009043</td>\n",
       "      <td>2.141674e-07</td>\n",
       "      <td>450.783530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>誒</th>\n",
       "      <td>0.008696</td>\n",
       "      <td>2.295785e-06</td>\n",
       "      <td>40.438362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>唔係</th>\n",
       "      <td>0.008280</td>\n",
       "      <td>1.771439e-07</td>\n",
       "      <td>498.988626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>去</th>\n",
       "      <td>0.008095</td>\n",
       "      <td>2.373822e-06</td>\n",
       "      <td>36.405895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>又</th>\n",
       "      <td>0.007063</td>\n",
       "      <td>1.461277e-07</td>\n",
       "      <td>515.960930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>喎</th>\n",
       "      <td>0.007037</td>\n",
       "      <td>2.433589e-07</td>\n",
       "      <td>308.673320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>話</th>\n",
       "      <td>0.007022</td>\n",
       "      <td>1.438579e-07</td>\n",
       "      <td>521.078880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>到</th>\n",
       "      <td>0.006844</td>\n",
       "      <td>8.394491e-08</td>\n",
       "      <td>870.320255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>會</th>\n",
       "      <td>0.006673</td>\n",
       "      <td>2.029190e-07</td>\n",
       "      <td>351.071237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>咗</th>\n",
       "      <td>0.006557</td>\n",
       "      <td>6.548948e-08</td>\n",
       "      <td>1068.903017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>嗰啲</th>\n",
       "      <td>0.006511</td>\n",
       "      <td>1.697272e-07</td>\n",
       "      <td>409.528406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>趕住</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_discipline</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>推遲</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_study</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arts</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boyscott</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>board</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>先輪</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>回音</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>六十萬</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>administrative_assistant</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dis</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_part</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>十一點鐘</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>杯轕</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>工作天</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Form_five_form_seven</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foul</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>form_five</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firsthon</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>留底</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discipline</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>律師</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>executive</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>請人</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engin</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>人選</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daniel</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>心得</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7022 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          mean_prob      var_prob      sat_val\n",
       "word                                                          \n",
       "係                          0.040375  2.509103e-06   171.783880\n",
       "啊                          0.031788  1.480112e-06   229.278062\n",
       "呢                          0.023315  1.641020e-06   151.674803\n",
       "我                          0.022638  2.498071e-06    96.744623\n",
       "噉                          0.020966  5.484555e-07   408.090326\n",
       "你                          0.019475  6.682196e-07   311.129658\n",
       "唔                          0.017604  2.046593e-06    91.825559\n",
       "都                          0.016951  2.823170e-07   640.964689\n",
       "佢                          0.016647  9.024077e-07   196.939591\n",
       "好                          0.016248  1.987688e-06    87.263850\n",
       "嘅                          0.015212  1.073943e-06   151.218510\n",
       "就                          0.015067  7.778589e-07   206.778066\n",
       "即係                         0.014606  1.427891e-06   109.199204\n",
       "𡃉                          0.014593  3.336680e-07   466.883536\n",
       "喇                          0.012000  4.938074e-07   259.427149\n",
       "個                          0.011656  1.697865e-07   732.866163\n",
       "囖                          0.010902  4.264800e-07   272.897773\n",
       "有                          0.010772  1.805896e-07   636.804754\n",
       "啲                          0.010661  2.918955e-07   389.911264\n",
       "一                          0.009043  2.141674e-07   450.783530\n",
       "誒                          0.008696  2.295785e-06    40.438362\n",
       "唔係                         0.008280  1.771439e-07   498.988626\n",
       "去                          0.008095  2.373822e-06    36.405895\n",
       "又                          0.007063  1.461277e-07   515.960930\n",
       "喎                          0.007037  2.433589e-07   308.673320\n",
       "話                          0.007022  1.438579e-07   521.078880\n",
       "到                          0.006844  8.394491e-08   870.320255\n",
       "會                          0.006673  2.029190e-07   351.071237\n",
       "咗                          0.006557  6.548948e-08  1068.903017\n",
       "嗰啲                         0.006511  1.697272e-07   409.528406\n",
       "...                             ...           ...          ...\n",
       "趕住                         0.000003  6.022469e-12  5625.303786\n",
       "any_discipline             0.000003  6.022469e-12  5625.303786\n",
       "推遲                         0.000003  6.022469e-12  5625.303786\n",
       "case_study                 0.000003  6.022469e-12  5625.303786\n",
       "arts                       0.000003  6.022469e-12  5625.303786\n",
       "boyscott                   0.000003  6.022469e-12  5625.303786\n",
       "board                      0.000003  6.022469e-12  5625.303786\n",
       "先輪                         0.000003  6.022469e-12  5625.303786\n",
       "回音                         0.000003  6.022469e-12  5625.303786\n",
       "六十萬                        0.000003  6.022469e-12  5625.303786\n",
       "administrative_assistant   0.000003  6.022469e-12  5625.303786\n",
       "dis                        0.000003  6.022469e-12  5625.303786\n",
       "first_part                 0.000003  6.022469e-12  5625.303786\n",
       "十一點鐘                       0.000003  6.022469e-12  5625.303786\n",
       "杯轕                         0.000003  6.022469e-12  5625.303786\n",
       "工作天                        0.000003  6.022469e-12  5625.303786\n",
       "Form_five_form_seven       0.000003  6.022469e-12  5625.303786\n",
       "foul                       0.000003  6.022469e-12  5625.303786\n",
       "form_five                  0.000003  6.022469e-12  5625.303786\n",
       "firsthon                   0.000003  6.022469e-12  5625.303786\n",
       "留底                         0.000003  6.022469e-12  5625.303786\n",
       "discipline                 0.000003  6.022469e-12  5625.303786\n",
       "律師                         0.000003  6.022469e-12  5625.303786\n",
       "executive                  0.000003  6.022469e-12  5625.303786\n",
       "even                       0.000003  6.022469e-12  5625.303786\n",
       "請人                         0.000003  6.022469e-12  5625.303786\n",
       "engin                      0.000003  6.022469e-12  5625.303786\n",
       "人選                         0.000003  6.022469e-12  5625.303786\n",
       "Daniel                     0.000003  6.022469e-12  5625.303786\n",
       "心得                         0.000003  6.022469e-12  5625.303786\n",
       "\n",
       "[7022 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stopwords.sort_values('mean_prob', ascending=False) # high mp\n",
    "# df_stopwords.sort_values('var_prob', ascending=False) # high var_prob\n",
    "# df_stopwords.sort_values('sat_val', ascending=False) # high var_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Create a stopword list using an information model\n",
    "### For details in the methodology behind, see \n",
    "#### `Zou et. al 2006, \"Automatic Construction of Chinese Stop Word Lists\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_instances</th>\n",
       "      <th>word_prob</th>\n",
       "      <th>text_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bandai</th>\n",
       "      <td>6</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSL</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMS</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Internet</th>\n",
       "      <td>7</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kelly</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          num_instances  word_prob  text_num\n",
       "word                                        \n",
       "Bandai                6   0.001929         0\n",
       "CSL                   1   0.000321         0\n",
       "IMS                   1   0.000321         0\n",
       "Internet              7   0.002250         0\n",
       "Kelly                 1   0.000321         0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the entropy for each word\n",
    "df_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entropy = df_words['word_prob'] * np.log2(1 / df_words['word_prob'])\n",
    "df_entropy.rename('entropy', inplace=True)\n",
    "df_entropy = pd.DataFrame(df_entropy)\n",
    "df_entropy.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stopwords['entropy'] = df_entropy.groupby('word')['entropy'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_prob</th>\n",
       "      <th>var_prob</th>\n",
       "      <th>sat_val</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>係</th>\n",
       "      <td>0.040375</td>\n",
       "      <td>2.509103e-06</td>\n",
       "      <td>171.783880</td>\n",
       "      <td>10.555034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>啊</th>\n",
       "      <td>0.031788</td>\n",
       "      <td>1.480112e-06</td>\n",
       "      <td>229.278062</td>\n",
       "      <td>8.947203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>呢</th>\n",
       "      <td>0.023315</td>\n",
       "      <td>1.641020e-06</td>\n",
       "      <td>151.674803</td>\n",
       "      <td>7.041081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>我</th>\n",
       "      <td>0.022638</td>\n",
       "      <td>2.498071e-06</td>\n",
       "      <td>96.744623</td>\n",
       "      <td>6.855643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>噉</th>\n",
       "      <td>0.020966</td>\n",
       "      <td>5.484555e-07</td>\n",
       "      <td>408.090326</td>\n",
       "      <td>6.648333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>你</th>\n",
       "      <td>0.019475</td>\n",
       "      <td>6.682196e-07</td>\n",
       "      <td>311.129658</td>\n",
       "      <td>6.248555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>都</th>\n",
       "      <td>0.016951</td>\n",
       "      <td>2.823170e-07</td>\n",
       "      <td>640.964689</td>\n",
       "      <td>5.693180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>唔</th>\n",
       "      <td>0.017604</td>\n",
       "      <td>2.046593e-06</td>\n",
       "      <td>91.825559</td>\n",
       "      <td>5.684710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>佢</th>\n",
       "      <td>0.016647</td>\n",
       "      <td>9.024077e-07</td>\n",
       "      <td>196.939591</td>\n",
       "      <td>5.473743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>好</th>\n",
       "      <td>0.016248</td>\n",
       "      <td>1.987688e-06</td>\n",
       "      <td>87.263850</td>\n",
       "      <td>5.337662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>就</th>\n",
       "      <td>0.015067</td>\n",
       "      <td>7.778589e-07</td>\n",
       "      <td>206.778066</td>\n",
       "      <td>5.064061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>𡃉</th>\n",
       "      <td>0.014593</td>\n",
       "      <td>3.336680e-07</td>\n",
       "      <td>466.883536</td>\n",
       "      <td>5.048811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>嘅</th>\n",
       "      <td>0.015212</td>\n",
       "      <td>1.073943e-06</td>\n",
       "      <td>151.218510</td>\n",
       "      <td>5.025743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>即係</th>\n",
       "      <td>0.014606</td>\n",
       "      <td>1.427891e-06</td>\n",
       "      <td>109.199204</td>\n",
       "      <td>4.771766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>喇</th>\n",
       "      <td>0.012000</td>\n",
       "      <td>4.938074e-07</td>\n",
       "      <td>259.427149</td>\n",
       "      <td>4.275243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>個</th>\n",
       "      <td>0.011656</td>\n",
       "      <td>1.697865e-07</td>\n",
       "      <td>732.866163</td>\n",
       "      <td>4.271518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>有</th>\n",
       "      <td>0.010772</td>\n",
       "      <td>1.805896e-07</td>\n",
       "      <td>636.804754</td>\n",
       "      <td>4.005579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>囖</th>\n",
       "      <td>0.010902</td>\n",
       "      <td>4.264800e-07</td>\n",
       "      <td>272.897773</td>\n",
       "      <td>3.932545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>啲</th>\n",
       "      <td>0.010661</td>\n",
       "      <td>2.918955e-07</td>\n",
       "      <td>389.911264</td>\n",
       "      <td>3.932360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>一</th>\n",
       "      <td>0.009043</td>\n",
       "      <td>2.141674e-07</td>\n",
       "      <td>450.783530</td>\n",
       "      <td>3.451904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>唔係</th>\n",
       "      <td>0.008280</td>\n",
       "      <td>1.771439e-07</td>\n",
       "      <td>498.988626</td>\n",
       "      <td>3.220658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>誒</th>\n",
       "      <td>0.008696</td>\n",
       "      <td>2.295785e-06</td>\n",
       "      <td>40.438362</td>\n",
       "      <td>2.999032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>又</th>\n",
       "      <td>0.007063</td>\n",
       "      <td>1.461277e-07</td>\n",
       "      <td>515.960930</td>\n",
       "      <td>2.844280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>話</th>\n",
       "      <td>0.007022</td>\n",
       "      <td>1.438579e-07</td>\n",
       "      <td>521.078880</td>\n",
       "      <td>2.823023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>去</th>\n",
       "      <td>0.008095</td>\n",
       "      <td>2.373822e-06</td>\n",
       "      <td>36.405895</td>\n",
       "      <td>2.801436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>到</th>\n",
       "      <td>0.006844</td>\n",
       "      <td>8.394491e-08</td>\n",
       "      <td>870.320255</td>\n",
       "      <td>2.789478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>喎</th>\n",
       "      <td>0.007037</td>\n",
       "      <td>2.433589e-07</td>\n",
       "      <td>308.673320</td>\n",
       "      <td>2.774838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>咗</th>\n",
       "      <td>0.006557</td>\n",
       "      <td>6.548948e-08</td>\n",
       "      <td>1068.903017</td>\n",
       "      <td>2.708267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>會</th>\n",
       "      <td>0.006673</td>\n",
       "      <td>2.029190e-07</td>\n",
       "      <td>351.071237</td>\n",
       "      <td>2.677750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>嗰啲</th>\n",
       "      <td>0.006511</td>\n",
       "      <td>1.697272e-07</td>\n",
       "      <td>409.528406</td>\n",
       "      <td>2.632954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>請人</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>親自</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_mark</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>十一點鐘</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>round</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>留底</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>文靜</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>全年</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nature</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>人選</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aim_at</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impression</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_interview</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>工作天</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>身在福中不知福</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arts</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>回音</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interviewer</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_discipline</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>佣金</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>心得</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agent</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>administrative_assistant</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>趕住</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marketing_and_and</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>驚訝</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>律師</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>突然之間</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>杯轕</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firsthon</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.022469e-12</td>\n",
       "      <td>5625.303786</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7022 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          mean_prob      var_prob      sat_val    entropy\n",
       "word                                                                     \n",
       "係                          0.040375  2.509103e-06   171.783880  10.555034\n",
       "啊                          0.031788  1.480112e-06   229.278062   8.947203\n",
       "呢                          0.023315  1.641020e-06   151.674803   7.041081\n",
       "我                          0.022638  2.498071e-06    96.744623   6.855643\n",
       "噉                          0.020966  5.484555e-07   408.090326   6.648333\n",
       "你                          0.019475  6.682196e-07   311.129658   6.248555\n",
       "都                          0.016951  2.823170e-07   640.964689   5.693180\n",
       "唔                          0.017604  2.046593e-06    91.825559   5.684710\n",
       "佢                          0.016647  9.024077e-07   196.939591   5.473743\n",
       "好                          0.016248  1.987688e-06    87.263850   5.337662\n",
       "就                          0.015067  7.778589e-07   206.778066   5.064061\n",
       "𡃉                          0.014593  3.336680e-07   466.883536   5.048811\n",
       "嘅                          0.015212  1.073943e-06   151.218510   5.025743\n",
       "即係                         0.014606  1.427891e-06   109.199204   4.771766\n",
       "喇                          0.012000  4.938074e-07   259.427149   4.275243\n",
       "個                          0.011656  1.697865e-07   732.866163   4.271518\n",
       "有                          0.010772  1.805896e-07   636.804754   4.005579\n",
       "囖                          0.010902  4.264800e-07   272.897773   3.932545\n",
       "啲                          0.010661  2.918955e-07   389.911264   3.932360\n",
       "一                          0.009043  2.141674e-07   450.783530   3.451904\n",
       "唔係                         0.008280  1.771439e-07   498.988626   3.220658\n",
       "誒                          0.008696  2.295785e-06    40.438362   2.999032\n",
       "又                          0.007063  1.461277e-07   515.960930   2.844280\n",
       "話                          0.007022  1.438579e-07   521.078880   2.823023\n",
       "去                          0.008095  2.373822e-06    36.405895   2.801436\n",
       "到                          0.006844  8.394491e-08   870.320255   2.789478\n",
       "喎                          0.007037  2.433589e-07   308.673320   2.774838\n",
       "咗                          0.006557  6.548948e-08  1068.903017   2.708267\n",
       "會                          0.006673  2.029190e-07   351.071237   2.677750\n",
       "嗰啲                         0.006511  1.697272e-07   409.528406   2.632954\n",
       "...                             ...           ...          ...        ...\n",
       "請人                         0.000003  6.022469e-12  5625.303786   0.002284\n",
       "親自                         0.000003  6.022469e-12  5625.303786   0.002284\n",
       "question_mark              0.000003  6.022469e-12  5625.303786   0.002284\n",
       "十一點鐘                       0.000003  6.022469e-12  5625.303786   0.002284\n",
       "round                      0.000003  6.022469e-12  5625.303786   0.002284\n",
       "留底                         0.000003  6.022469e-12  5625.303786   0.002284\n",
       "文靜                         0.000003  6.022469e-12  5625.303786   0.002284\n",
       "全年                         0.000003  6.022469e-12  5625.303786   0.002284\n",
       "nature                     0.000003  6.022469e-12  5625.303786   0.002284\n",
       "人選                         0.000003  6.022469e-12  5625.303786   0.002284\n",
       "aim_at                     0.000003  6.022469e-12  5625.303786   0.002284\n",
       "impression                 0.000003  6.022469e-12  5625.303786   0.002284\n",
       "in_interview               0.000003  6.022469e-12  5625.303786   0.002284\n",
       "工作天                        0.000003  6.022469e-12  5625.303786   0.002284\n",
       "身在福中不知福                    0.000003  6.022469e-12  5625.303786   0.002284\n",
       "arts                       0.000003  6.022469e-12  5625.303786   0.002284\n",
       "回音                         0.000003  6.022469e-12  5625.303786   0.002284\n",
       "interviewer                0.000003  6.022469e-12  5625.303786   0.002284\n",
       "any_discipline             0.000003  6.022469e-12  5625.303786   0.002284\n",
       "佣金                         0.000003  6.022469e-12  5625.303786   0.002284\n",
       "心得                         0.000003  6.022469e-12  5625.303786   0.002284\n",
       "agent                      0.000003  6.022469e-12  5625.303786   0.002284\n",
       "administrative_assistant   0.000003  6.022469e-12  5625.303786   0.002284\n",
       "趕住                         0.000003  6.022469e-12  5625.303786   0.002284\n",
       "marketing_and_and          0.000003  6.022469e-12  5625.303786   0.002284\n",
       "驚訝                         0.000003  6.022469e-12  5625.303786   0.002284\n",
       "律師                         0.000003  6.022469e-12  5625.303786   0.002284\n",
       "突然之間                       0.000003  6.022469e-12  5625.303786   0.002284\n",
       "杯轕                         0.000003  6.022469e-12  5625.303786   0.002284\n",
       "firsthon                   0.000003  6.022469e-12  5625.303786   0.002284\n",
       "\n",
       "[7022 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stopwords.sort_values('entropy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre: attribute_type must be 'sat_val', 'mean_prob', 'var_prob', 'entropy'\n",
    "def findRank(attribute_type, bool_ascending):\n",
    "    return df_stopwords.sort_values(\n",
    "        [attribute_type], ascending=bool_ascending ).reset_index().reset_index().set_index(\n",
    "        'word')[['index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank_sat_val = findRank('sat_val', True) # The higher the\n",
    "df_rank_mean_prob = findRank('mean_prob', False)\n",
    "df_rank_var_prob = findRank('var_prob', False)\n",
    "df_rank_entropy = findRank('entropy', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank = pd.DataFrame({\n",
    "    'sat_val_rank' : df_rank_sat_val['index'], \n",
    "    'mean_prob_rank' : df_rank_mean_prob['index'], \n",
    "    'var_prob_rank' : df_rank_var_prob['index'], \n",
    "    'entropy_rank' : df_rank_entropy['index'] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank['weight'] = df_rank.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank.sort_values('weight', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output stop words\n",
    "# this list might need some further human cleaning\n",
    "df_rank['index'].head(50).to_csv(DICT_PATH + \\\n",
    "    r'hkcancorpus_stopwords.txt', \n",
    "    sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile HMM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dataframes, axis=0, ignore_index=True)\n",
    "df = df[['file_num', 'text', 'pos']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check if string is an ascii\n",
    "def string_is_ascii(string):\n",
    "    try:\n",
    "        string.encode(encoding='ascii')\n",
    "    except UnicodeEncodeError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# preprocessing function for BMES tagging of words\n",
    "#\n",
    "# It separates words to a list of characters\n",
    "# To preserve the ascii word,\n",
    "# find the first pointer ascii character position\n",
    "# find the last pointer ascii character position\n",
    "# concatenate ascii characters in the sublist, \n",
    "# removing empty strings and white spaces in between\n",
    "# parameter: word - word\n",
    "# returns: a list of tokens\n",
    "def tokenize_word(word):\n",
    "    char_list = list(word)\n",
    "#     print(\"Word is separated to : \" + str(char_list))\n",
    "\n",
    "    first_ascii_pos = []\n",
    "    last_ascii_pos = []\n",
    "    \n",
    "    ascii_flag = False\n",
    "    for i, c in enumerate(char_list):\n",
    "#         print(\"The current character is %s\" %c)\n",
    "        if string_is_ascii(c):           \n",
    "            if ascii_flag == False:\n",
    "#                 print(\"ascii set to true\")\n",
    "                first_ascii_pos.append(i)\n",
    "                ascii_flag = True\n",
    "            if i == len(char_list) - 1:\n",
    "                last_ascii_pos.append(len(char_list))\n",
    "        else:\n",
    "            if ascii_flag == True:\n",
    "#                 print(\"ascii set to false\")\n",
    "                last_ascii_pos.append(i)\n",
    "                ascii_flag = False\n",
    "        \n",
    "    if len(first_ascii_pos): # if array is not empty\n",
    "#         print(first_ascii_pos[::-1])\n",
    "#         print(last_ascii_pos[::-1])\n",
    "        for i, j in zip(first_ascii_pos[::-1], last_ascii_pos[::-1]):\n",
    "#             print(i, j)\n",
    "            char_list[i:j] = list(\n",
    "                filter(None, \"\".join(char_list[i:j]).split(\" \") ) )\n",
    "    return char_list\n",
    "\n",
    "    \n",
    "\n",
    "# function to tag words using the\n",
    "# BMES (begin, middle, end, single) tagging system\n",
    "# precondition: string must not be empty\n",
    "# returns list of separated words and corresponding\n",
    "# BMES tags\n",
    "def tagWord_BMES(word):\n",
    "    word_length = len(word)\n",
    "    assert(word_length)\n",
    "    bmes_list = []\n",
    "    \n",
    "    word_list = tokenize_word(word)\n",
    "    if len(word_list) == 1:\n",
    "        bmes_list.append(\"S\")\n",
    "    else:\n",
    "        for i, w in enumerate(word_list):\n",
    "            if i == 0:\n",
    "                bmes_list.append(\"B\")\n",
    "            elif i == len(word_list) - 1:\n",
    "                bmes_list.append(\"E\")\n",
    "            else:\n",
    "                bmes_list.append(\"M\")\n",
    "        \n",
    "    return bmes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test cases\n",
    "# print(tokenize_word('你office land過牆梯'))\n",
    "# print(tokenize_word('office'))\n",
    "# print(tokenize_word('你office'))\n",
    "# print(tokenize_word('hello過牆梯world'))\n",
    "# print(tokenize_word('hello過牆梯world過牆'))\n",
    "# print(tokenize_word('你過牆梯'))\n",
    "# print(tokenize_word('Hello  World'))\n",
    "\n",
    "# print(tagWord_BMES('你有過牆梯')) # BMMME\n",
    "# print(tagWord_BMES('office')) # S\n",
    "# print(tagWord_BMES('你office')) # BE\n",
    "# print(tagWord_BMES('office牆')) # BE\n",
    "# print(tagWord_BMES('Hello World')) # BE\n",
    "# print(tagWord_BMES('有有')) # BE\n",
    "# print(tagWord_BMES('有')) # S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper to count total number of start instances\n",
    "def countTotalStartInstances(start_dict):\n",
    "    total = 0\n",
    "    for _, value in start_dict.items():\n",
    "        total += value\n",
    "    return total\n",
    "\n",
    "\n",
    "# create training algorithm to calculate \n",
    "# emission (BMES->word) and transition (BMES->BMES)\n",
    "# probabilities\n",
    "# returns: a tuple of prob_trans, prob_emit, and prob_start\n",
    "def trainingHMM_BMESTagging(text_lists):\n",
    "    emission = {}\n",
    "    transition = {}\n",
    "    context = {} \n",
    "    start = {}\n",
    "    \n",
    "    # for prob_*.* files in jieba\n",
    "    prob_trans = collections.defaultdict(dict)\n",
    "    prob_emit = collections.defaultdict(dict)\n",
    "    prob_start = {}\n",
    "    \n",
    "    \n",
    "    # this is for the training part\n",
    "    for line_list in text_lists:\n",
    "        previous = '<s>'\n",
    "        if previous not in context:\n",
    "            context[previous] = 0\n",
    "        context[previous] += 1\n",
    "        \n",
    "        for j, character in enumerate(line_list):\n",
    "#             print(\"The entry contains %s\" % character)\n",
    "            text_bmesTags_list = tagWord_BMES(character)\n",
    "            if j == 0:\n",
    "                start_tag = text_bmesTags_list[0]\n",
    "                if start_tag not in start:\n",
    "                    start[start_tag] = 0\n",
    "                start[start_tag] += 1\n",
    "        \n",
    "            for i, bmesTag in enumerate(text_bmesTags_list):\n",
    "                \n",
    "                transition_bigram = previous + \" \" + bmesTag\n",
    "                if transition_bigram not in transition:\n",
    "                    transition[transition_bigram] = 0\n",
    "                transition[transition_bigram] += 1\n",
    "\n",
    "                if bmesTag not in context:\n",
    "                    context[bmesTag] = 0\n",
    "                context[bmesTag] += 1\n",
    "\n",
    "                bigram_emission = bmesTag + \" \" + character[i]\n",
    "                if bigram_emission not in emission:\n",
    "                    emission[bigram_emission] = 0\n",
    "                emission[bigram_emission] += 1\n",
    "\n",
    "                previous = bmesTag\n",
    "            \n",
    "        bigram_transition = previous + \" </s>\"\n",
    "        if bigram_transition not in transition:\n",
    "            transition[bigram_transition] = 0\n",
    "        transition[bigram_transition] += 1\n",
    "\n",
    "    # output transition, emission and start probabilities\n",
    "#     print(context)\n",
    "    for key, value in transition.items():\n",
    "        previous_tag, current_tag = key.split(\" \", maxsplit=1)\n",
    "        if previous_tag != '<s>' and current_tag != \"</s>\":\n",
    "            prob_trans[previous_tag][current_tag] = math.log2(float(value)/context[previous_tag])\n",
    "#         print(\"Transition probability of %s is %.15f\" % (key, math.log2(float(value)/context[previous_tag]) ) )        \n",
    "#     print(\"\\n\\n\\n\")\n",
    "    \n",
    "    for key, value in emission.items():\n",
    "        tag, word = key.split(\" \", maxsplit=1)\n",
    "#         print(\"Context contains %d instances\" % context[tag])\n",
    "#         print(\"tag is %s, which emits %s, with emission probability of %.15f\\n\" % (\n",
    "#             tag, word,  math.log2(float(value)/context[tag])))\n",
    "        prob_emit[tag][word] = math.log2(float(value)/context[tag])\n",
    "    \n",
    "#     print(\"Start dict contains\" + str(start))\n",
    "    for tag, value in start.items():\n",
    "        prob_start[tag] = math.log2(float(value)/countTotalStartInstances(start))\n",
    "    prob_start[\"M\"] = -3.14e100 # minimum float value defined in jieba (MIN_FLOAT)\n",
    "    prob_start[\"E\"] = -3.14e100 # minimum float value defined in jieba (MIN_FLOAT)\n",
    "    \n",
    "    return dict(prob_trans), dict(prob_emit), prob_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_trans1, prob_emit1, prob_start1 = trainingHMM_BMESTagging(df.text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training algorithm to calculate \n",
    "# emission (pos->word) and transition (pos-pos)\n",
    "# probabilities\n",
    "def trainingHMM_POSTagging(text_lists, posTags_lists):\n",
    "    emission = {}\n",
    "    transition = {}\n",
    "    context = {} \n",
    "    start = {}\n",
    "    char_state = {}\n",
    "    \n",
    "    # for char_state_tab.*, prob_*.* files in jieba\n",
    "    prob_trans = collections.defaultdict(dict)\n",
    "    prob_emit = collections.defaultdict(dict)\n",
    "    prob_start = {}\n",
    "    \n",
    "    # existing tagset may contain a combination of tags\n",
    "    pos_tagset1 = [pos_tag for posTag_list in posTags_lists for pos_tag in posTag_list]\n",
    "    pos_tagset2 = ['ag', 'a', 'ad', 'an', 'bg', 'b', 'c', 'dg', 'd', \n",
    "        'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'mg', 'm', 'ng', 'n', \n",
    "        'nr', 'ns', 'nt', 'nx', 'nz', 'o', 'p', 'qg', 'q', 'rg', 'r', \n",
    "        's', 'tg', 't', 'ug', 'u', 'vg', 'v', 'vd', 'vn', 'w', 'x', \n",
    "        'yg', 'y', 'z'] # official HKCanCor tagset\n",
    "    unique_pos_tagset = set(pos_tagset1 + pos_tagset2)\n",
    "    bmes_tagset = {'B', 'M', 'E', 'S'}\n",
    "    \n",
    "    # this is for the training part\n",
    "    for line_list, linePosTags_list in zip(text_lists, posTags_lists):\n",
    "        previous = ('<s>') # start sentence tag\n",
    "        if previous not in context:\n",
    "            context[previous] = 0\n",
    "        context[previous] += 1\n",
    "       \n",
    "        for j, (character, pos_tag) in enumerate(\n",
    "            zip(line_list, linePosTags_list) ):\n",
    "#             print(\"The entry contains %s with tag %s \" % (character, pos_tag) )\n",
    "            character_bmesTags_list = tagWord_BMES(character)\n",
    "            character_token_list = tokenize_word(character)\n",
    "            \n",
    "            # build up start dictionary\n",
    "            if j == 0:\n",
    "                start_tag = character_bmesTags_list[0]\n",
    "                if (start_tag, pos_tag) not in start:\n",
    "                    start[(start_tag, pos_tag)] = 0\n",
    "                start[(start_tag, pos_tag)] += 1\n",
    "        \n",
    "            # build up transition, emission dictionaries\n",
    "            for i, (token, bmesTag) in enumerate(\n",
    "                zip(character_token_list, character_bmesTags_list)):\n",
    "                \n",
    "                tag_pair = (bmesTag, pos_tag)\n",
    "                \n",
    "                transition_bigram = (previous, tag_pair)\n",
    "                if transition_bigram not in transition:\n",
    "                    transition[transition_bigram] = 0\n",
    "                transition[transition_bigram] += 1\n",
    "\n",
    "                if tag_pair not in context:\n",
    "                    context[tag_pair] = 0\n",
    "                context[tag_pair] += 1\n",
    "\n",
    "                bigram_emission = (tag_pair, token)\n",
    "                if bigram_emission not in emission:\n",
    "                    emission[bigram_emission] = 0\n",
    "                emission[bigram_emission] += 1\n",
    "                \n",
    "                if token not in char_state:\n",
    "                    char_state[token] = []\n",
    "                char_state[token].append(tag_pair)\n",
    "                    \n",
    "                \n",
    "                previous = tag_pair\n",
    "            \n",
    "        bigram_transition = (previous, \"</s>\")\n",
    "        if bigram_transition not in transition:\n",
    "            transition[bigram_transition] = 0\n",
    "        transition[bigram_transition] += 1\n",
    "        \n",
    "    \n",
    "# output transition, emission and start probabilities\n",
    "#     print(context)\n",
    "    for (previous_tag_pair, current_tag_pair), value in transition.items():\n",
    "        if previous_tag_pair != ('<s>') and current_tag_pair != (\"</s>\"):\n",
    "            prob_trans[previous_tag_pair][current_tag_pair] = math.log2(float(value)/context[previous_tag_pair])\n",
    "#         print(\"Transition probability of %s is %.15f\" % (key, math.log2(float(value)/context[previous_tag]) ) )        \n",
    "#     print(\"\\n\\n\\n\")\n",
    "    for bmes_tag in bmes_tagset: # do this for empty tag pairs \n",
    "        for pos_tag in unique_pos_tagset:\n",
    "            if (bmes_tag, pos_tag) not in prob_trans:\n",
    "                prob_trans[(bmes_tag, pos_tag)] = {}\n",
    "                \n",
    "    \n",
    "    for (token, tag_pair_list) in char_state.items():\n",
    "        char_state[token] = tuple(set(tag_pair_list)) # only keep unique tag sets\n",
    "        \n",
    "    \n",
    "    for (tag_pair, word), value in emission.items():\n",
    "#         print(\"Context contains %d instances\" % context[tag_pair])\n",
    "#         print(\"tag is %s, which emits %s, with emission probability of %.15f\\n\" % (\n",
    "#             tag, word,  math.log2(float(value)/context[tag_pair])))\n",
    "        prob_emit[tag_pair][word] = math.log2(float(value)/context[tag_pair])\n",
    "    \n",
    "    for bmes_tag in bmes_tagset: # do this for empty tag pairs \n",
    "        for pos_tag in unique_pos_tagset:\n",
    "            if (bmes_tag, pos_tag) not in prob_emit:\n",
    "                prob_emit[(bmes_tag, pos_tag)] = {}\n",
    "\n",
    "                \n",
    "#     print(\"Start dict contains\" + str(start))\n",
    "    for tag_pair, value in start.items():\n",
    "        prob_start[tag_pair] = math.log2(float(value)/countTotalStartInstances(start))\n",
    "    for bmes_tag in bmes_tagset: # do this for empty tag pairs \n",
    "        for pos_tag in unique_pos_tagset:\n",
    "            if (bmes_tag, pos_tag) not in prob_start:\n",
    "                prob_start[(bmes_tag, pos_tag)] = -3.14e100 # minimum float value defined in jieba (MIN_FLOAT)\n",
    "    \n",
    "    return dict(prob_trans), dict(prob_emit), prob_start, char_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_trans2, prob_emit2, prob_start2, char_state2 = trainingHMM_POSTagging(df.text.tolist(), df.pos.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_state2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s4, s5, s6, s7 = trainingHMM_POSTagging([['重', '有得', '搞']], [['d', 'vu', 'v']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Output prob_trans, prob_emit, prob_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputDictionary(filename, prob_dict):\n",
    "    with open(OUTPUT_PATH + filename, 'w', encoding='utf-8') as f:\n",
    "        with redirect_stdout(f):\n",
    "            print(\"P=\", end='')\n",
    "            pprint(prob_dict) \n",
    "    assert(f.closed)\n",
    "\n",
    "def pickleDictionary(filename, prob_dict):\n",
    "    with open(OUTPUT_PATH + filename, 'wb') as f:\n",
    "        # jieba uses protocol 0 encoding for its pickle files\n",
    "        pickle.dump(prob_dict, f, protocol=0)\n",
    "    assert(f.closed)\n",
    "    \n",
    "def depickleDictionary(filename):\n",
    "    with open(OUTPUT_PATH + filename, 'rb') as f:\n",
    "        prob_dict = pickle.load(f, encoding='utf-8')\n",
    "    assert(f.closed)\n",
    "    return prob_dict\n",
    "    \n",
    "outputDictionary(\"posseg/prob_trans.py\", prob_trans2)\n",
    "outputDictionary(\"posseg/prob_emit.py\", prob_emit2)\n",
    "outputDictionary(\"posseg/prob_start.py\", prob_start2)\n",
    "outputDictionary(\"posseg/char_state_tab.py\", char_state2)\n",
    "\n",
    "pickleDictionary(\"posseg/prob_trans.p\", prob_trans2)\n",
    "pickleDictionary(\"posseg/prob_emit.p\", prob_emit2)\n",
    "pickleDictionary(\"posseg/prob_start.p\", prob_start2)\n",
    "pickleDictionary(\"posseg/char_state_tab.p\", char_state2)\n",
    "\n",
    "outputDictionary(\"finalseg/prob_trans.py\", prob_trans1)\n",
    "outputDictionary(\"finalseg/prob_emit.py\", prob_emit1)\n",
    "outputDictionary(\"finalseg/prob_start.py\", prob_start1)\n",
    "\n",
    "pickleDictionary(\"finalseg/prob_trans.p\", prob_trans1)\n",
    "pickleDictionary(\"finalseg/prob_emit.p\", prob_emit1)\n",
    "pickleDictionary(\"finalseg/prob_start.p\", prob_start1)\n",
    "\n",
    "\n",
    "# s1 = depickleDictionary(\"finalseg/prob_trans.p\")\n",
    "# s2 = depickleDictionary(\"finalseg/prob_emit.p\")\n",
    "# s3 = depickleDictionary(\"finalseg/prob_start.p\")\n",
    "\n",
    "# s1 = depickleDictionary(\"posseg/prob_trans.p\")\n",
    "# s2 = depickleDictionary(\"posseg/prob_emit.p\")\n",
    "# s3 = depickleDictionary(\"posseg/prob_start.p\")\n",
    "# s4 = depickleDictionary(\"posseg/char_state_tab.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Dictionary Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put everything in Pandas\n",
    "# This is not necessary, but \n",
    "# it shows the layouts neatly\n",
    "df_full = pd.concat(dataframes).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_num</th>\n",
       "      <th>pos</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[v, v, n, y, nr, nr]</td>\n",
       "      <td>[有冇, 養, 寵物, 𡃉, 王, 美美]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[v]</td>\n",
       "      <td>[有]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[v, u, m, q, n]</td>\n",
       "      <td>[養, 咗, 兩, 隻, 狗]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[a, y]</td>\n",
       "      <td>[真, 㗎]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[r, n, y]</td>\n",
       "      <td>[乜嘢, 樣, 𡃉]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>[r, n, y]</td>\n",
       "      <td>[乜嘢, 狗, 啊]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>[e, m, q, nz, m, q, nz]</td>\n",
       "      <td>[誒, 一, 隻, 西施, 一, 隻, 拉薩]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>[nz, y, r, n, y]</td>\n",
       "      <td>[西施, 𠻺, 點樣, 樣, 𡃉]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>[d, a, q, d, a, n, r]</td>\n",
       "      <td>[好, 細, 隻, 好, 多, 毛, 嗰啲]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>[nz, r, c, r, v, u, r, q, n]</td>\n",
       "      <td>[西施, 佢, 但係, 我, 剪, 晒, 佢, 啲, 毛]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>[e]</td>\n",
       "      <td>[嘩]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>[r, r, d, a, y]</td>\n",
       "      <td>[乜, 你, 咁, 殘忍, 𡃉]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>[v]</td>\n",
       "      <td>[唔係]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>[a, y, t]</td>\n",
       "      <td>[熱, 嚹, 夏天]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>[t, y, y]</td>\n",
       "      <td>[夏天, 吖, 嗎]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>[c, n, vu, v, y, y]</td>\n",
       "      <td>[不過, 熱天, 要, 剪, 㗎, 嗎]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>[c, v, vu, v, u, q, n]</td>\n",
       "      <td>[如果, 唔係, 會, 甩, 晒, 啲, 毛]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>[a, r, d, v, v, n, p, r, y, y]</td>\n",
       "      <td>[熱, 你, 都, 涼, 開, 冷氣, 俾, 佢, 吖, 嗎]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>[v, n]</td>\n",
       "      <td>[開, 冷氣]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>[t, d, v, y, y]</td>\n",
       "      <td>[夜晚, 先, 開, 㗎, 嗎]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>[v, q, ng, v, q, n, n, v, r, y, y]</td>\n",
       "      <td>[有, 個, 冷, 有, 個, 冷氣, 掣, 俾, 佢, 㗎, 嗎]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>[r, d, d, d, d, v, q, n, y]</td>\n",
       "      <td>[你, 都, 唔, 都, 唔, 愛錫, 啲, 生物, 𠸏]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>[r, d, r, v, y, d, v, n]</td>\n",
       "      <td>[哩個, 唔, 哩個, 唔係, 𠸏, 都, 冇, 生命]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>[d, v, r, q, n, r]</td>\n",
       "      <td>[咪, 俾, 你, 個, 心, 佢]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>[c, r, v, y]</td>\n",
       "      <td>[噉, 你, 唔係, 𠺝]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>[c, r, c, r, vu, v, r, y, q, n]</td>\n",
       "      <td>[噉, 你, 噉, 你, 要, 照顧, 佢, 𠿪, 啲, 寵物]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>[r, n, v, y, y]</td>\n",
       "      <td>[我, 阿媽, 喺度, 吖, 嗎]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>[r, n, v, n, y]</td>\n",
       "      <td>[我, 阿媽, 喺, 屋企, 啊]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>[v, v, y]</td>\n",
       "      <td>[係, 係, 咩]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>[r, n, v, r, q, n, y]</td>\n",
       "      <td>[你, 阿媽, 照顧, 你, 啲, 寵物, 㗎]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15852</th>\n",
       "      <td>57</td>\n",
       "      <td>[v, y, v, y]</td>\n",
       "      <td>[係, 啊, 係, 啊]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15853</th>\n",
       "      <td>57</td>\n",
       "      <td>[v, c, d, v, n, a, u, y, q, n, vu, v, v, y]</td>\n",
       "      <td>[唔係, 即係, 比較, 對, 人, 多, 啲, 囖, 個, 工作, 會, 係, 係, 喇]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15854</th>\n",
       "      <td>57</td>\n",
       "      <td>[e, e, e, e, e]</td>\n",
       "      <td>[喀, 喀, 喀, 喀, 喀]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15855</th>\n",
       "      <td>57</td>\n",
       "      <td>[e, e, e]</td>\n",
       "      <td>[喀, 喀, 喀]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15856</th>\n",
       "      <td>57</td>\n",
       "      <td>[c, c, r, d, c, r, q, xn, d, d, a, r, u]</td>\n",
       "      <td>[噉, 所以, 佢, 就, 即係, 佢哋, 啲, computer_knowledge, 都...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15857</th>\n",
       "      <td>57</td>\n",
       "      <td>[e]</td>\n",
       "      <td>[哦]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15858</th>\n",
       "      <td>57</td>\n",
       "      <td>[c, e, v, y, r, d, v, c, d, q, n, d, v, u, xa,...</td>\n",
       "      <td>[即係, 誒, 係, 嘞, 佢, 就, 話, 所以, 其實, 份, 工, 就, 包, 埋, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15859</th>\n",
       "      <td>57</td>\n",
       "      <td>[v]</td>\n",
       "      <td>[係]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15860</th>\n",
       "      <td>57</td>\n",
       "      <td>[c, xa, r, xn, y, d, v, vu, r, v, r, p, v, c, ...</td>\n",
       "      <td>[噉, technical, 嗰, part, 呢, 就, 係, 要, 你, 知道, 點樣,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15861</th>\n",
       "      <td>57</td>\n",
       "      <td>[e]</td>\n",
       "      <td>[喀]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15862</th>\n",
       "      <td>57</td>\n",
       "      <td>[c, r, d, vu, v, u, xv, r, n, v, d, v, r, q, x...</td>\n",
       "      <td>[噉, 你, 就, 要, 識, 得, test, 嗰個, 人, 識, 唔, 識, 哩, 套,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15863</th>\n",
       "      <td>57</td>\n",
       "      <td>[c, xd, r, r, d, v, y, r, d, v, v, u, xv, r, y]</td>\n",
       "      <td>[即係, even, 你, 自己, 唔, 識, 喇, 你, 都, 要, 識, 得, test...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15864</th>\n",
       "      <td>57</td>\n",
       "      <td>[e, e, e, e]</td>\n",
       "      <td>[喀, 喀, 喀, 喀]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15865</th>\n",
       "      <td>57</td>\n",
       "      <td>[v, y]</td>\n",
       "      <td>[係, 嘞]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15866</th>\n",
       "      <td>57</td>\n",
       "      <td>[c, r, vu, d, vu, v, r, y, d, q, xn, r]</td>\n",
       "      <td>[噉, 佢, 會, 唔, 會, 教, 你, 𡃉, 其實, 個, software, 點樣]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15867</th>\n",
       "      <td>57</td>\n",
       "      <td>[v, y, v, y]</td>\n",
       "      <td>[係, 啊, 係, 啊]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15868</th>\n",
       "      <td>57</td>\n",
       "      <td>[c, r, d, v, r, v, r, vu, v, d, a, n, y, r, v,...</td>\n",
       "      <td>[噉, 佢, 就, 話, 佢, 話, 點解, 會, 請, 咁, 少, 人, 呢, 佢, 話,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15869</th>\n",
       "      <td>57</td>\n",
       "      <td>[r, v, c, v, u, ng, y, y, r, v]</td>\n",
       "      <td>[佢, 話, 但係, 頂, 晒, 窿, 𡃉, 嚹, 噉, 講]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15870</th>\n",
       "      <td>57</td>\n",
       "      <td>[r, v, c, c, r, v, r, vu, xv, m, n, v, r, n, y...</td>\n",
       "      <td>[佢, 話, 因為, 即係, 佢, 話, 佢, 會, spend, 好多, 時間, 教, 你...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15871</th>\n",
       "      <td>57</td>\n",
       "      <td>[e, e, e]</td>\n",
       "      <td>[喀, 喀, 喀]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15872</th>\n",
       "      <td>57</td>\n",
       "      <td>[e, c, d, d, d, a, n, v, d, a, y]</td>\n",
       "      <td>[啊, 噉, 其實, 都, 幾, 多, 嘢, 學, 幾, 好, 啊]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15873</th>\n",
       "      <td>57</td>\n",
       "      <td>[v, y, v, y, c, c, v, y, c, d, d, vu, v, y, d,...</td>\n",
       "      <td>[係, 啊, 係, 啊, 噉, 所以, 係, 喇, 噉, 都, 幾, 想, 做, 𠸏, 其實...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15874</th>\n",
       "      <td>57</td>\n",
       "      <td>[e, c, vu, r, v, y, r, q]</td>\n",
       "      <td>[哎吔, 噉, 希望, 你, 得, 喇, 哩, 份]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15875</th>\n",
       "      <td>57</td>\n",
       "      <td>[v, y, v, y]</td>\n",
       "      <td>[係, 喇, 係, 喇]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15876</th>\n",
       "      <td>57</td>\n",
       "      <td>[v, y]</td>\n",
       "      <td>[係, 啊]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15877</th>\n",
       "      <td>57</td>\n",
       "      <td>[v, c, v, e, e, e, c, v, c, y, r, t, d, v, r, ...</td>\n",
       "      <td>[係, 噉, 不如, 唉, 唉, 唉, 噉, 不如, 噉, 喇, 我, 遲啲, 再, 揾, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15878</th>\n",
       "      <td>57</td>\n",
       "      <td>[a, y, a, y, a, y]</td>\n",
       "      <td>[好, 啊, 好, 啊, 好, 啊]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15879</th>\n",
       "      <td>57</td>\n",
       "      <td>[c, r, d, v, y]</td>\n",
       "      <td>[噉, 你, 都, 係, 啊]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15880</th>\n",
       "      <td>57</td>\n",
       "      <td>[a, y]</td>\n",
       "      <td>[好, 喇]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15881</th>\n",
       "      <td>57</td>\n",
       "      <td>[a, y, a, y, xa]</td>\n",
       "      <td>[好, 喇, 好, 喇, OK]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15882 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_num                                                pos  \\\n",
       "0             0                               [v, v, n, y, nr, nr]   \n",
       "1             0                                                [v]   \n",
       "2             0                                    [v, u, m, q, n]   \n",
       "3             0                                             [a, y]   \n",
       "4             0                                          [r, n, y]   \n",
       "5             0                                          [r, n, y]   \n",
       "6             0                            [e, m, q, nz, m, q, nz]   \n",
       "7             0                                   [nz, y, r, n, y]   \n",
       "8             0                              [d, a, q, d, a, n, r]   \n",
       "9             0                       [nz, r, c, r, v, u, r, q, n]   \n",
       "10            0                                                [e]   \n",
       "11            0                                    [r, r, d, a, y]   \n",
       "12            0                                                [v]   \n",
       "13            0                                          [a, y, t]   \n",
       "14            0                                          [t, y, y]   \n",
       "15            0                                [c, n, vu, v, y, y]   \n",
       "16            0                             [c, v, vu, v, u, q, n]   \n",
       "17            0                     [a, r, d, v, v, n, p, r, y, y]   \n",
       "18            0                                             [v, n]   \n",
       "19            0                                    [t, d, v, y, y]   \n",
       "20            0                 [v, q, ng, v, q, n, n, v, r, y, y]   \n",
       "21            0                        [r, d, d, d, d, v, q, n, y]   \n",
       "22            0                           [r, d, r, v, y, d, v, n]   \n",
       "23            0                                 [d, v, r, q, n, r]   \n",
       "24            0                                       [c, r, v, y]   \n",
       "25            0                    [c, r, c, r, vu, v, r, y, q, n]   \n",
       "26            0                                    [r, n, v, y, y]   \n",
       "27            0                                    [r, n, v, n, y]   \n",
       "28            0                                          [v, v, y]   \n",
       "29            0                              [r, n, v, r, q, n, y]   \n",
       "...         ...                                                ...   \n",
       "15852        57                                       [v, y, v, y]   \n",
       "15853        57        [v, c, d, v, n, a, u, y, q, n, vu, v, v, y]   \n",
       "15854        57                                    [e, e, e, e, e]   \n",
       "15855        57                                          [e, e, e]   \n",
       "15856        57           [c, c, r, d, c, r, q, xn, d, d, a, r, u]   \n",
       "15857        57                                                [e]   \n",
       "15858        57  [c, e, v, y, r, d, v, c, d, q, n, d, v, u, xa,...   \n",
       "15859        57                                                [v]   \n",
       "15860        57  [c, xa, r, xn, y, d, v, vu, r, v, r, p, v, c, ...   \n",
       "15861        57                                                [e]   \n",
       "15862        57  [c, r, d, vu, v, u, xv, r, n, v, d, v, r, q, x...   \n",
       "15863        57    [c, xd, r, r, d, v, y, r, d, v, v, u, xv, r, y]   \n",
       "15864        57                                       [e, e, e, e]   \n",
       "15865        57                                             [v, y]   \n",
       "15866        57            [c, r, vu, d, vu, v, r, y, d, q, xn, r]   \n",
       "15867        57                                       [v, y, v, y]   \n",
       "15868        57  [c, r, d, v, r, v, r, vu, v, d, a, n, y, r, v,...   \n",
       "15869        57                    [r, v, c, v, u, ng, y, y, r, v]   \n",
       "15870        57  [r, v, c, c, r, v, r, vu, xv, m, n, v, r, n, y...   \n",
       "15871        57                                          [e, e, e]   \n",
       "15872        57                  [e, c, d, d, d, a, n, v, d, a, y]   \n",
       "15873        57  [v, y, v, y, c, c, v, y, c, d, d, vu, v, y, d,...   \n",
       "15874        57                          [e, c, vu, r, v, y, r, q]   \n",
       "15875        57                                       [v, y, v, y]   \n",
       "15876        57                                             [v, y]   \n",
       "15877        57  [v, c, v, e, e, e, c, v, c, y, r, t, d, v, r, ...   \n",
       "15878        57                                 [a, y, a, y, a, y]   \n",
       "15879        57                                    [c, r, d, v, y]   \n",
       "15880        57                                             [a, y]   \n",
       "15881        57                                   [a, y, a, y, xa]   \n",
       "\n",
       "                                                    text  \n",
       "0                                  [有冇, 養, 寵物, 𡃉, 王, 美美]  \n",
       "1                                                    [有]  \n",
       "2                                        [養, 咗, 兩, 隻, 狗]  \n",
       "3                                                 [真, 㗎]  \n",
       "4                                             [乜嘢, 樣, 𡃉]  \n",
       "5                                             [乜嘢, 狗, 啊]  \n",
       "6                                [誒, 一, 隻, 西施, 一, 隻, 拉薩]  \n",
       "7                                      [西施, 𠻺, 點樣, 樣, 𡃉]  \n",
       "8                                 [好, 細, 隻, 好, 多, 毛, 嗰啲]  \n",
       "9                          [西施, 佢, 但係, 我, 剪, 晒, 佢, 啲, 毛]  \n",
       "10                                                   [嘩]  \n",
       "11                                      [乜, 你, 咁, 殘忍, 𡃉]  \n",
       "12                                                  [唔係]  \n",
       "13                                            [熱, 嚹, 夏天]  \n",
       "14                                            [夏天, 吖, 嗎]  \n",
       "15                                  [不過, 熱天, 要, 剪, 㗎, 嗎]  \n",
       "16                               [如果, 唔係, 會, 甩, 晒, 啲, 毛]  \n",
       "17                       [熱, 你, 都, 涼, 開, 冷氣, 俾, 佢, 吖, 嗎]  \n",
       "18                                               [開, 冷氣]  \n",
       "19                                      [夜晚, 先, 開, 㗎, 嗎]  \n",
       "20                    [有, 個, 冷, 有, 個, 冷氣, 掣, 俾, 佢, 㗎, 嗎]  \n",
       "21                         [你, 都, 唔, 都, 唔, 愛錫, 啲, 生物, 𠸏]  \n",
       "22                          [哩個, 唔, 哩個, 唔係, 𠸏, 都, 冇, 生命]  \n",
       "23                                    [咪, 俾, 你, 個, 心, 佢]  \n",
       "24                                         [噉, 你, 唔係, 𠺝]  \n",
       "25                      [噉, 你, 噉, 你, 要, 照顧, 佢, 𠿪, 啲, 寵物]  \n",
       "26                                     [我, 阿媽, 喺度, 吖, 嗎]  \n",
       "27                                     [我, 阿媽, 喺, 屋企, 啊]  \n",
       "28                                             [係, 係, 咩]  \n",
       "29                              [你, 阿媽, 照顧, 你, 啲, 寵物, 㗎]  \n",
       "...                                                  ...  \n",
       "15852                                       [係, 啊, 係, 啊]  \n",
       "15853     [唔係, 即係, 比較, 對, 人, 多, 啲, 囖, 個, 工作, 會, 係, 係, 喇]  \n",
       "15854                                    [喀, 喀, 喀, 喀, 喀]  \n",
       "15855                                          [喀, 喀, 喀]  \n",
       "15856  [噉, 所以, 佢, 就, 即係, 佢哋, 啲, computer_knowledge, 都...  \n",
       "15857                                                [哦]  \n",
       "15858  [即係, 誒, 係, 嘞, 佢, 就, 話, 所以, 其實, 份, 工, 就, 包, 埋, ...  \n",
       "15859                                                [係]  \n",
       "15860  [噉, technical, 嗰, part, 呢, 就, 係, 要, 你, 知道, 點樣,...  \n",
       "15861                                                [喀]  \n",
       "15862  [噉, 你, 就, 要, 識, 得, test, 嗰個, 人, 識, 唔, 識, 哩, 套,...  \n",
       "15863  [即係, even, 你, 自己, 唔, 識, 喇, 你, 都, 要, 識, 得, test...  \n",
       "15864                                       [喀, 喀, 喀, 喀]  \n",
       "15865                                             [係, 嘞]  \n",
       "15866      [噉, 佢, 會, 唔, 會, 教, 你, 𡃉, 其實, 個, software, 點樣]  \n",
       "15867                                       [係, 啊, 係, 啊]  \n",
       "15868  [噉, 佢, 就, 話, 佢, 話, 點解, 會, 請, 咁, 少, 人, 呢, 佢, 話,...  \n",
       "15869                    [佢, 話, 但係, 頂, 晒, 窿, 𡃉, 嚹, 噉, 講]  \n",
       "15870  [佢, 話, 因為, 即係, 佢, 話, 佢, 會, spend, 好多, 時間, 教, 你...  \n",
       "15871                                          [喀, 喀, 喀]  \n",
       "15872                 [啊, 噉, 其實, 都, 幾, 多, 嘢, 學, 幾, 好, 啊]  \n",
       "15873  [係, 啊, 係, 啊, 噉, 所以, 係, 喇, 噉, 都, 幾, 想, 做, 𠸏, 其實...  \n",
       "15874                         [哎吔, 噉, 希望, 你, 得, 喇, 哩, 份]  \n",
       "15875                                       [係, 喇, 係, 喇]  \n",
       "15876                                             [係, 啊]  \n",
       "15877  [係, 噉, 不如, 唉, 唉, 唉, 噉, 不如, 噉, 喇, 我, 遲啲, 再, 揾, ...  \n",
       "15878                                 [好, 啊, 好, 啊, 好, 啊]  \n",
       "15879                                    [噉, 你, 都, 係, 啊]  \n",
       "15880                                             [好, 喇]  \n",
       "15881                                   [好, 喇, 好, 喇, OK]  \n",
       "\n",
       "[15882 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.DataFrame(np.sum(df_full.apply(lambda row: list(zip(\n",
    "    row['text'], row['pos']) ), axis=1).values) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.columns = ['word', 'pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>有冇</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>養</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>寵物</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>王</td>\n",
       "      <td>nr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>美美</td>\n",
       "      <td>nr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>有</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>養</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>咗</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>兩</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>隻</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>狗</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>真</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>㗎</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>乜嘢</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>樣</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>乜嘢</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>狗</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>啊</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>誒</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>一</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>隻</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>西施</td>\n",
       "      <td>nz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>一</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>隻</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>拉薩</td>\n",
       "      <td>nz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>西施</td>\n",
       "      <td>nz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>𠻺</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>點樣</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121756</th>\n",
       "      <td>如果</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121757</th>\n",
       "      <td>一</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121758</th>\n",
       "      <td>有</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121759</th>\n",
       "      <td>乜嘢</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121760</th>\n",
       "      <td>消息</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121761</th>\n",
       "      <td>你</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121762</th>\n",
       "      <td>就</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121763</th>\n",
       "      <td>話</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121764</th>\n",
       "      <td>俾</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121765</th>\n",
       "      <td>我</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121766</th>\n",
       "      <td>知</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121767</th>\n",
       "      <td>喇</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121768</th>\n",
       "      <td>好</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121769</th>\n",
       "      <td>啊</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121770</th>\n",
       "      <td>好</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121771</th>\n",
       "      <td>啊</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121772</th>\n",
       "      <td>好</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121773</th>\n",
       "      <td>啊</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121774</th>\n",
       "      <td>噉</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121775</th>\n",
       "      <td>你</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121776</th>\n",
       "      <td>都</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121777</th>\n",
       "      <td>係</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121778</th>\n",
       "      <td>啊</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121779</th>\n",
       "      <td>好</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121780</th>\n",
       "      <td>喇</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121781</th>\n",
       "      <td>好</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121782</th>\n",
       "      <td>喇</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121783</th>\n",
       "      <td>好</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121784</th>\n",
       "      <td>喇</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121785</th>\n",
       "      <td>OK</td>\n",
       "      <td>xa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121786 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word pos\n",
       "0        有冇   v\n",
       "1         養   v\n",
       "2        寵物   n\n",
       "3         𡃉   y\n",
       "4         王  nr\n",
       "5        美美  nr\n",
       "6         有   v\n",
       "7         養   v\n",
       "8         咗   u\n",
       "9         兩   m\n",
       "10        隻   q\n",
       "11        狗   n\n",
       "12        真   a\n",
       "13        㗎   y\n",
       "14       乜嘢   r\n",
       "15        樣   n\n",
       "16        𡃉   y\n",
       "17       乜嘢   r\n",
       "18        狗   n\n",
       "19        啊   y\n",
       "20        誒   e\n",
       "21        一   m\n",
       "22        隻   q\n",
       "23       西施  nz\n",
       "24        一   m\n",
       "25        隻   q\n",
       "26       拉薩  nz\n",
       "27       西施  nz\n",
       "28        𠻺   y\n",
       "29       點樣   r\n",
       "...     ...  ..\n",
       "121756   如果   c\n",
       "121757    一   m\n",
       "121758    有   v\n",
       "121759   乜嘢   r\n",
       "121760   消息   n\n",
       "121761    你   r\n",
       "121762    就   d\n",
       "121763    話   v\n",
       "121764    俾   p\n",
       "121765    我   r\n",
       "121766    知   v\n",
       "121767    喇   y\n",
       "121768    好   a\n",
       "121769    啊   y\n",
       "121770    好   a\n",
       "121771    啊   y\n",
       "121772    好   a\n",
       "121773    啊   y\n",
       "121774    噉   c\n",
       "121775    你   r\n",
       "121776    都   d\n",
       "121777    係   v\n",
       "121778    啊   y\n",
       "121779    好   a\n",
       "121780    喇   y\n",
       "121781    好   a\n",
       "121782    喇   y\n",
       "121783    好   a\n",
       "121784    喇   y\n",
       "121785   OK  xa\n",
       "\n",
       "[121786 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full.groupby(['word','pos'], sort=False).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the columns according to Jieba Dictionary layout\n",
    "df_full = df_full[['word', 'count', 'pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>有冇</td>\n",
       "      <td>159</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>養</td>\n",
       "      <td>118</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>寵物</td>\n",
       "      <td>8</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>𡃉</td>\n",
       "      <td>1784</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>王</td>\n",
       "      <td>4</td>\n",
       "      <td>nr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  count pos\n",
       "0   有冇    159   v\n",
       "1    養    118   v\n",
       "2   寵物      8   n\n",
       "3    𡃉   1784   y\n",
       "4    王      4  nr"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_with_digits = df_full[df_full['word'].str.contains(r\"[0-9]+\", regex=True)]['word'].values\n",
    "\n",
    "# # define what to exclude from the set words_with_digits\n",
    "# words_with_digits = set(words_with_digits).difference({'One2Free', 'A1', '323', '121', 'N64', '東方188' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_with_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full['word'] = df_full['word'].apply(fixCantoneseJupingsInWordColumn, fix_list=words_with_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full[df_full['word'].str.contains(r\"[0-9]+\", regex=True)]['word'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full[df_full['word'].str.contains(r\"[A-Za-z]+\", regex=True)]['word'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>寵物</td>\n",
       "      <td>8</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>王</td>\n",
       "      <td>4</td>\n",
       "      <td>nr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>美美</td>\n",
       "      <td>1</td>\n",
       "      <td>nr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>狗</td>\n",
       "      <td>30</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>樣</td>\n",
       "      <td>66</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  count pos\n",
       "2    寵物      8   n\n",
       "4     王      4  nr\n",
       "5    美美      1  nr\n",
       "10    狗     30   n\n",
       "14    樣     66   n"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nouns = df_full[df_full.pos.str.contains('^n|[^va]n', regex=True)]\n",
    "df_nouns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_others = df_full[~df_full.isin(df_nouns)].dropna()\n",
    "df_others['count'] = df_others['count'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nouns.word.to_csv(\n",
    "    DICT_PATH + r'nouns.txt', \n",
    "    sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_others.word.to_csv(\n",
    "    DICT_PATH + r'others.txt', \n",
    "    sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_csv(\n",
    "    DICT_PATH + r'hkcantonesedict.txt', \n",
    "    sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
